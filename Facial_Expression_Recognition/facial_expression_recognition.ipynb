{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets, preprocessing, feature_extraction\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import linear_model, svm, metrics, ensemble, tree, ensemble\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pandas\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "facecascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "facedict = {}\n",
    "actions = {}\n",
    "emotions = [\"anger\",\"disgust\",\"fear\", \"happy\",\"neutral\",\"sadness\",\"surprise\"]\n",
    "df = pandas.read_excel(\"emotion_audio.xlsx\") #open Excel file\n",
    "actions[\"anger\"] = [x for x in df.anger.dropna()] #We need de dropna() when columns are uneven in length, which creates NaN values at missing places. The OS won't know what to do with these if we try to open them.\n",
    "actions[\"disgust\"] = [x for x in df.disgust.dropna()]\n",
    "actions[\"fear\"] = [x for x in df.fear.dropna()]\n",
    "actions[\"happy\"] = [x for x in df.happy.dropna()]\n",
    "actions[\"neutral\"] = [x for x in df.neutral.dropna()]\n",
    "actions[\"sadness\"] = [x for x in df.sadness.dropna()]\n",
    "actions[\"surprise\"] = [x for x in df.surprise.dropna()]\n",
    "\n",
    "\n",
    "def open_stuff(filename): #Open the file, credit to user4815162342, on the stackoverflow link in the text above\n",
    "    if sys.platform == \"win32\":\n",
    "        os.startfile(filename)\n",
    "    else:\n",
    "        opener =\"open\" if sys.platform == \"darwin\" else \"xdg-open\"\n",
    "        subprocess.call([opener, filename])\n",
    "\n",
    "def update(emotions):\n",
    "        run_recognizer(emotions)\n",
    "        print(\"saving model\")\n",
    "        fishface.save(\"trained_emoclassifier.xml\")\n",
    "        print(\"model saved!\")\n",
    "\n",
    "def crop_face(clahe_image, face):\n",
    "    for (x, y, w, h) in face:\n",
    "        faceslice = clahe_image[y:y+h, x:x+w]\n",
    "        faceslice = cv2.resize(faceslice, (350, 350))\n",
    "    facedict[\"face%s\" %(len(facedict)+1)] = faceslice\n",
    "    return faceslice\n",
    "\n",
    "def update_model(emotions):\n",
    "    print(\"Model update mode active\")\n",
    "    check_folders(emotions)\n",
    "    for i in range(0, len(emotions)):\n",
    "        save_face(emotions[i])\n",
    "    print(\"collected images, looking good! Now updating model...\")\n",
    "    #update(emotions)\n",
    "    print(\"Done!\")\n",
    "    cv2.destroyWindow(\"preview\")\n",
    "    cv2.destroyWindow(\"webcam\")\n",
    "\n",
    "def check_folders(emotions): #check if folder infrastructure is there, create if absent\n",
    "    for x in emotions:\n",
    "        if os.path.exists(\"sorted_set\\\\%s\" %x):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(\"sorted_set\\\\%s\" %x)\n",
    "\n",
    "def save_face(emotion):\n",
    "    print(\"\\n\\nplease look \" + emotion + \" when the timer expires and keep the expression stable until instructed otherwise.\")\n",
    "    actionlist = [x for x in actions[emotion]] #get list of actions/files for detected emotion\n",
    "    random.shuffle(actionlist) #Randomly shuffle the list\n",
    "    open_stuff(actionlist[0])\n",
    "    for i in range(0,5):#Timer to give you time to read what emotion to express\n",
    "        print(5-i)\n",
    "        time.sleep(1)\n",
    "    while len(facedict.keys()) < 11: #Grab 15 images for each emotion\n",
    "        grab_webcamframe()\n",
    "    for x in facedict.keys(): #save contents of dictionary to files\n",
    "        cv2.imwrite(\"sorted_set\\\\%s\\\\%s.jpg\" %(emotion, len(glob.glob(\"sorted_set\\\\%s\\\\*\" %emotion))), facedict[x])\n",
    "    facedict.clear() #clear dictionary so that the next emotion can be stored\n",
    "\n",
    "def grab_webcamframe():\n",
    "      \n",
    "    while True:\n",
    "        if vc.isOpened(): # try to get the first frame\n",
    "            rval, frame = vc.read()\n",
    "        else:\n",
    "            rval = False\n",
    "        cv2.imshow(\"preview\", frame)\n",
    "        key = cv2.waitKey(40)\n",
    "        if key == 27: # exit on ESC\n",
    "            break\n",
    "        if key == 32:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale to improve detection speed and accuracy\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            clahe_image = clahe.apply(gray)\n",
    "\n",
    "            #Run classifier on frame\n",
    "            face = facecascade.detectMultiScale(clahe_image, scaleFactor=1.1, minNeighbors=15, minSize=(10, 10), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "            for (x, y, w, h) in face: #Draw rectangle around detected faces\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2) #draw it on \"frame\", (coordinates), (size), (RGB color), thickness 2\n",
    "\n",
    "            if len(face) == 1: #Use simple check if one face is detected, or multiple (measurement error unless multiple persons on image)\n",
    "                faceslice = crop_face(clahe_image, face)\n",
    "                cv2.imshow(\"webcam\", frame)\n",
    "                return faceslice#slice face from image\n",
    "                #cv2.imshow(\"detect\", faceslice) #display sliced face\n",
    "                #for x in facedict.keys():\n",
    "                    #cv2.imwrite(\"real_set\\\\%s.jpg\" %x, facedict[x])\n",
    "            else:\n",
    "                print(\"no/multiple faces detected, passing over frame\")\n",
    "\n",
    "            #cv2.imshow(\"webcam\", frame) #Display frame\n",
    "\n",
    "    cv2.destroyWindow(\"preview\")\n",
    "    cv2.destroyWindow(\"webcam\")\n",
    "\n",
    "\n",
    "update_model(emotions)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''img_width, img_height = 350, 350\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'sorted_set'\n",
    "\n",
    "nb_train_samples = 1011\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "def save_bottlebeck_features():\n",
    "    #Function to compute VGG-16 CNN for image feature extraction.\n",
    "    train_target = []\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    generator_train = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    for i in generator_train.filenames:\n",
    "        train_target.append(i[:])\n",
    "     \n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator_train, nb_train_samples // batch_size)\n",
    "   \n",
    "    bottleneck_features_train =  bottleneck_features_train.reshape(1011,51200)\n",
    "    \n",
    "   \n",
    "    np.save(open('data_features.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('data_labels.npy', 'wb'), np.array(train_target))\n",
    "save_bottlebeck_features()   ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data_features.npy\")\n",
    "target = np.load(\"data_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = [target[i].split('\\\\')[0] for i in range(target.shape[0])]\n",
    "type(data_y)\n",
    "data_y = pd.DataFrame(data_y)\n",
    "type(data_y)\n",
    "data_y.columns = ['label']\n",
    "Counter(data_y['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\"label\": {\"ger\": 0, \"sgust\": 1, \"ar\": 2, \"ppy\": 3,\n",
    "                                  \"utral\": 4, \"dness\": 5, \"rprise\":6 }}\n",
    "data_y.replace(classes, inplace=True)\n",
    "print(data_y.head())\n",
    "print(type(data_y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, test_df, y_train, y_test = train_test_split(data, data_y, stratify=data_y, test_size=0.05)\n",
    "train_df, cv_df, y_train, y_cv = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)\n",
    "print(train_df.shape)\n",
    "print(cv_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# it returns a dict, keys as class labels and values as the number of data points in that class\n",
    "train_class_distribution = y_train['label'].value_counts().sortlevel()\n",
    "test_class_distribution = y_test['label'].value_counts().sortlevel()\n",
    "cv_class_distribution = y_cv['label'].value_counts().sortlevel()\n",
    "\n",
    "my_colors = 'rgbkymc'\n",
    "train_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in train data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ref: argsort https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
    "# -(train_class_distribution.values): the minus sign will give us in decreasing order\n",
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',train_class_distribution.values[i], '(', np.round((train_class_distribution.values[i]/train_df.shape[0]*100), 3), '%)')\n",
    "\n",
    "    \n",
    "print('-'*80)\n",
    "my_colors = 'rgbkymc'\n",
    "test_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in test data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ref: argsort https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
    "# -(train_class_distribution.values): the minus sign will give us in decreasing order\n",
    "sorted_yi = np.argsort(-test_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',test_class_distribution.values[i], '(', np.round((test_class_distribution.values[i]/test_df.shape[0]*100), 3), '%)')\n",
    "\n",
    "print('-'*80)\n",
    "my_colors = 'rgbkymc'\n",
    "cv_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in cross validation data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ref: argsort https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
    "# -(train_class_distribution.values): the minus sign will give us in decreasing order\n",
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',cv_class_distribution.values[i], '(', np.round((cv_class_distribution.values[i]/cv_df.shape[0]*100), 3), '%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    \n",
    "    labels = [0,1,2,3,4,5,6]\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*20, \"Confusion matrix\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*20, \"Precision matrix (Columm Sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*20, \"Recall matrix (Row sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_len = test_df.shape[0]\n",
    "cv_data_len = cv_df.shape[0]\n",
    "\n",
    "# we create a output array that has exactly same size as the CV data\n",
    "cv_predicted_y = np.zeros((cv_data_len,7))\n",
    "for i in range(cv_data_len):\n",
    "    rand_probs = np.random.rand(1,7)\n",
    "    cv_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Cross Validation Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))\n",
    "\n",
    "\n",
    "# Test-Set error.\n",
    "#we create a output array that has exactly same as the test data\n",
    "test_predicted_y = np.zeros((test_data_len,7))\n",
    "for i in range(test_data_len):\n",
    "    rand_probs = np.random.rand(1,7)\n",
    "    test_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test,test_predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(test_predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 1)]\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_df, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_df)\n",
    "    \n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_df, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_df, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predict_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 1)]\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    clf.fit(train_df, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_df)\n",
    "    \n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "clf.fit(train_df, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_df, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predict_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "alpha = [5, 11, 15, 21, 31, 41, 51, 99]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for alpha =\", i)\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(train_df, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df, y_train)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_df)\n",
    "    cv_log_error_array.append(log_loss(y_cv, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
    "    print(\"Log Loss :\",log_loss(y_cv, sig_clf_probs)) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "clf.fit(train_df, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_df, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "#predicted_y =np.argmax(predict_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_webcam_features():\n",
    "    img_width, img_height = 350, 350\n",
    "    top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "    train_data_dir = 'real_set'\n",
    "\n",
    "    nb_train_samples = 1\n",
    "\n",
    "    epochs = 50\n",
    "    batch_size = 1\n",
    "    \n",
    "    #Function to compute VGG-16 CNN for image feature extraction.\n",
    "    train_target = []\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    generator_train = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    for i in generator_train.filenames:\n",
    "        train_target.append(i[2:])\n",
    "     \n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator_train, nb_train_samples // batch_size)\n",
    "   \n",
    "    bottleneck_features_train =  bottleneck_features_train.reshape(1,51200)\n",
    "    print(bottleneck_features_train.shape)\n",
    "    np.save(open('real_features.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('real_labels.npy', 'wb'), np.array(train_target))\n",
    "    prediction()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction():\n",
    "    predictions = []\n",
    "    features = np.load('real_features.npy')\n",
    "    labels = np.load('real_labels.npy')\n",
    "    predictions  = sig_clf.predict_proba(features)\n",
    "    \n",
    "    print(predictions)\n",
    "    emotion = []\n",
    "    emotion = sig_clf.predict(features)\n",
    "    for i in range(len(emotion)):\n",
    "        if emotion[i] == 0:\n",
    "             print(\"I guess you are angry\")\n",
    "        elif emotion[i] == 1:\n",
    "             print(\"I guess you are disgust\")\n",
    "        elif emotion[i] == 2:\n",
    "             print(\"I guess you are fear\")\n",
    "        elif emotion[i] == 3:\n",
    "             print(\"I guess you are happy\")   \n",
    "        elif emotion[i] == 4:\n",
    "             print(\"I guess you are neutral\")\n",
    "        elif emotion[i] == 5:\n",
    "             print(\"I guess you are sad\")\n",
    "        elif emotion[i] == 6:\n",
    "             print(\"I guess you are surprise\") \n",
    "    cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "facecascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def crop_face(clahe_image, face):\n",
    "    for (x, y, w, h) in face:\n",
    "        faceslice = clahe_image[y:y+h, x:x+w]\n",
    "        faceslice = cv2.resize(faceslice, (350, 350))\n",
    "    facedict[\"face%s\" %(len(facedict)+1)] = faceslice\n",
    "    return faceslice\n",
    "\n",
    "while True:\n",
    "    facedict = {}\n",
    "    if vc.isOpened(): # try to get the first frame\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    key = cv2.waitKey(40)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "    if key == 32:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale to improve detection speed and accuracy\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        clahe_image = clahe.apply(gray)\n",
    "\n",
    "        #Run classifier on frame\n",
    "        face = facecascade.detectMultiScale(clahe_image, scaleFactor=1.1, minNeighbors=15, minSize=(10, 10), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        for (x, y, w, h) in face: #Draw rectangle around detected faces\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2) #draw it on \"frame\", (coordinates), (size), (RGB color), thickness 2\n",
    "\n",
    "        if len(face) == 1: #Use simple check if one face is detected, or multiple (measurement error unless multiple persons on image)\n",
    "            faceslice = crop_face(clahe_image, face)\n",
    "    \n",
    "             \n",
    "            for x in facedict.keys():\n",
    "                cv2.imwrite(\"real_set\\\\1\\\\%s.jpg\" %x, facedict[x])\n",
    "                save_webcam_features()\n",
    "                \n",
    "        else:\n",
    "            print(\"no/multiple faces detected, passing over frame\")\n",
    "\n",
    "        #cv2.imshow(\"webcam\", frame) #Display frame\n",
    "        \n",
    "cv2.destroyWindow(\"preview\")\n",
    "#cv2.destroyWindow(\"webcam\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
